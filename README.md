# concourse-gcs-resource
A quick an dirty concourse resource to get and put into Google Cloud Storage using metadata short lived credentials

I tried to stick to the S3 resource conventions when possible. 

Versions objects in a GCS bucket, by pattern-matching filenames to identify
version numbers.

## Source Configuration

* `bucket`: *Required.* The name of the bucket.

### File Names

* `versioned_file`: *Required* versioning must be enabled for your GCS bucket then
  you can keep the file name the same and upload new versions of your file. This property is the path to the file
  in your GCS bucket.

#### Dealing with directories rather than files

  *** NOTE *** You can configure it to download or put a path rather than a file. This means, it may not work with object names ending with / (I haven't tested), but I think it is worth the downside. 

When your `versioned_file` is a path (ends with /), the get step will skip the metadata download (will not show any version in the UI) and will download the whole content of that path (latest versions).

Similarly, if you configure put to use a path source ending with / or using *, it will upload all those files to the specified path. The subsequent get step will default to NOOP because it would otherwise need to validate every single upload. You will see some "DIRECTORY" or "SKIP_DOWNLOAD" references which help the resource understand there is nothing to do in that step.

For example

```yaml
resources:
- name: all-releases
  type: gcs
  source:
    bucket: releases
    versioned_file: directory_on_gcs/
```

``` yaml
- get: all-releases
```

``` yaml
- put: all-releases
  params:
    file: path/to/releases/*
```

### Initial state

If no resource versions exist you can set up this resource to emit an initial version with a specified content. This won't create a real resource in S3 but only create an initial version for Concourse. The resource file will be created as usual when you `get` a resource with an initial version.

* `initial_version`: *Optional.* This will be the resource version.

By default the resource file will be created with no content when `get` runs. You can set the content by using one of the following options:

* `initial_content_text`: *Optional.* Initial content as a string.

* `initial_content_binary`: *Optional.* You can pass binary content as a base64 encoded string.

**NOTE:** initial_content_text and initial_content_binary are mutually exclusive. If both are provided the file will contain the content text value.

## Behavior

### `check`: Extract versions from the bucket.

Objects will be found via GCS bucket versioning. Your bucket must be versioned.


### `in`: Fetch an object from the bucket.

Places the following files in the destination:

* `(filename)`: The file fetched from the bucket (if `skip_download` is not `true`).

* `object_metadata.yml`: A file containing the metadata for that object as it is generated by `gcloud storage describe`

#### Parameters

* `skip_download`: *Optional.* Skip downloading object from S3. Same parameter as source configuration but used to define/override by get. Value needs to be a true/false string.

* `unpack`: *Optional.* If true and the file is an archive (tar, gzipped tar, other gzipped file, or zip), unpack the file. Gzipped tarballs will be both ungzipped and untarred. It is ignored when `get` is running on the initial version.

### `out`: Upload an object to the bucket.

Given a file specified by `file`, upload it to the GCS bucket. The new file will be uploaded as
a new version of that file.

**NOTE:** Known issues. gcloud does not return the object version when pushing new versions. Because of that it is not garanteed that the out ref value is the exact version that has just been pushed, since there is a race condition in the interim between pushing and checking the version. 
#### Parameters

* `file`: *Required.* Path to the file to upload, provided by an output of a task.
  If multiple files are matched by the glob, an error is raised. The file which
  matches will be uploaded as a new version of `versioned_file`

## Example Configuration

### Resource

The file is being [versioned by GCS](https://cloud.google.com/storage/docs/object-versioning)

``` yaml
resource_types:
- name: gcs
  type: docker-image
  source:
    repository: juanlugm/concourse-gcs-resource

resources:
- name: release
  type: gcs
  source:
    bucket: releases
    versioned_file: directory_on_gcs/release.tgz
```

### Resource with initial version
``` yaml
resources:
- name: release
  type: gcs
  source:
    bucket: releases
    versioned_file: directory_on_gcs/release.tgz
    initial_version: version_value    # This is not used anywhere other than to allow a first execution with get or trigger a job
    initial_content_text: some_content_for_the_file  # This will be put in the file for that first job execution
```

### Plan

``` yaml
- get: release
```

``` yaml
- put: release
  params:
    file: path/to/release-*.tgz
```

## Authentication
This resource relies on running in GCS infrastructure, with access to the host metadata endpoint to retrieve a valid token when a service account has been configured for that host. 

See GCP documentation on how to achieve this. [doc](https://cloud.google.com/compute/docs/access/authenticate-workloads)

See [a nice explanation here](https://alexanderhose.com/understanding-the-gcp-metadata-service-and-service-accounts/#:~:text=One%20of%20the%20most%20prominent,without%20exposing%20long%2Dlived%20credentials.)

## Development

### Prerequisites

* Bash is *required* 
* docker is *required*

### Running the tests

Oops. No tests yet.

### Contributing

Please make all pull requests to the `main` branch