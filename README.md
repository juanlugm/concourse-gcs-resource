# concourse-gcs-resource
A quick an dirty concourse resource to get and put into Google Cloud Storage using metadata short lived credentials

I tried to stick to the S3 resource conventions when possible. 

Versions objects in a GCS bucket, by pattern-matching filenames to identify
version numbers.

## Source Configuration

* `bucket`: *Required.* The name of the bucket.

### File Names

* `versioned_file`: *Required* versioning must be enabled for your GCS bucket then
  you can keep the file name the same and upload new versions of your file. This property is the path to the file
  in your GCS bucket.

### Initial state

If no resource versions exist you can set up this resource to emit an initial version with a specified content. This won't create a real resource in S3 but only create an initial version for Concourse. The resource file will be created as usual when you `get` a resource with an initial version.

* `initial_version`: *Optional.* This will be the resource version.

By default the resource file will be created with no content when `get` runs. You can set the content by using one of the following options:

* `initial_content_text`: *Optional.* Initial content as a string.

* `initial_content_binary`: *Optional.* You can pass binary content as a base64 encoded string.

## Behavior

### `check`: Extract versions from the bucket.

Objects will be found via GCS bucket versioning. Your bucket must be versioned.


### `in`: Fetch an object from the bucket.

Places the following files in the destination:

* `(filename)`: The file fetched from the bucket (if `skip_download` is not `true`).

* `object_metadata.yml`: A file containing the metadata for that object as it is generated by `gcloud storage describe`

#### Parameters

* `skip_download`: *Optional.* Skip downloading object from S3. Same parameter as source configuration but used to define/override by get. Value needs to be a true/false string.

* `unpack`: *Optional.* If true and the file is an archive (tar, gzipped tar, other gzipped file, or zip), unpack the file. Gzipped tarballs will be both ungzipped and untarred. It is ignored when `get` is running on the initial version.

### `out`: Upload an object to the bucket.

Given a file specified by `file`, upload it to the GCS bucket. The new file will be uploaded as
a new version of that file.

#### Parameters

* `file`: *Required.* Path to the file to upload, provided by an output of a task.
  If multiple files are matched by the glob, an error is raised. The file which
  matches will be uploaded as a new version of `versioned_file`

## Example Configuration

### Resource

The file is being [versioned by GCS](https://cloud.google.com/storage/docs/object-versioning)

``` yaml
resource_types:
- name: gcs
  type: docker-image
  source:
    repository: juanlugm/concourse-gcs-resource

resources:
- name: release
  type: gcs
  source:
    bucket: releases
    versioned_file: directory_on_gcs/release.tgz
```

### Plan

``` yaml
- get: release
```

``` yaml
- put: release
  params:
    file: path/to/release-*.tgz
```

## Authentication
This resource relies on running in GCS infrastructure, with access to the host metadata endpoint to retrieve a valid token when a service account has been configured for that host. 

See GCP documentation on how to achieve this. [doc](https://cloud.google.com/compute/docs/access/authenticate-workloads)

See [a nice explanation here](https://alexanderhose.com/understanding-the-gcp-metadata-service-and-service-accounts/#:~:text=One%20of%20the%20most%20prominent,without%20exposing%20long%2Dlived%20credentials.)

## Development

### Prerequisites

* Bash is *required* 
* docker is *required*

### Running the tests

Oops. No tests yet.

### Contributing

Please make all pull requests to the `main` branch